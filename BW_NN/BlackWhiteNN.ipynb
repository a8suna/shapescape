{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9cdd912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Lambda\n",
    "import timm\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "import os \n",
    "from torchvision.io import decode_image\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6245fd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Version: 3.13.5 | packaged by Anaconda, Inc. | (main, Jun 12 2025, 16:37:03) [MSC v.1929 64 bit (AMD64)]\n",
      "PyTorch version 2.10.0+cpu\n",
      "Torchvision version 0.25.0+cpu\n",
      "Numpy version 2.1.3\n",
      "Pandas version 2.2.3\n"
     ]
    }
   ],
   "source": [
    "print('System Version:', sys.version)\n",
    "print('PyTorch version', torch.__version__)\n",
    "print('Torchvision version', torchvision.__version__)\n",
    "print('Numpy version', np.__version__)\n",
    "print('Pandas version', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78b4ef9",
   "metadata": {},
   "source": [
    "Loading in **custom** dataset using .csv label approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b54cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resizing images to be 28 x 28 pixels\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Grayscale(1),transforms.Resize((28,28))])\n",
    "\n",
    "\n",
    "class BlackAndWhite(Dataset):\n",
    "    def __init__(self, labels, images, transform=None): # This initates the data\n",
    "        self.labels = pd.read_csv(labels)\n",
    "        self.data_dir = ImageFolder(images, transform=transform)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels) #checks the length of the data\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_dir[idx] # This is for the labelling the idx is the tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5926bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BlackAndWhite(\n",
    "    labels=\"labels.csv\",\n",
    "    images=\"bwImages\",\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c358fd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking total number of images in dataset\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f505d371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# checking images and labels work\n",
    "\n",
    "image, label = dataset[0]\n",
    "print(image.shape)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "156fae1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "0\n",
      "torch.Size([1, 28, 28])\n",
      "0\n",
      "torch.Size([1, 28, 28])\n",
      "0\n",
      "torch.Size([1, 28, 28])\n",
      "0\n",
      "torch.Size([1, 28, 28])\n",
      "0\n",
      "torch.Size([1, 28, 28])\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    image, label = dataset[i]\n",
    "    print(image.shape)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344835f9",
   "metadata": {},
   "source": [
    "Splitting images into training_set and testing_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "460ad891",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = 18\n",
    "testing_size = 6\n",
    "\n",
    "training_set, testing_set = random_split(\n",
    "    dataset,\n",
    "    [training_size, testing_size]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd95c62",
   "metadata": {},
   "source": [
    "Preparing data for training with DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d48a7078",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_set, batch_size=1, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_set, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "806d09ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([1, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79193fea",
   "metadata": {},
   "source": [
    "Getting device for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb2cc0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38923302",
   "metadata": {},
   "source": [
    "## Building the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7756f6",
   "metadata": {},
   "source": [
    "Defining neural network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93ab55ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc24d7a1",
   "metadata": {},
   "source": [
    "Creating an instance of NeuralNetwork and moving it to the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fecd2444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=16, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11785cf6",
   "metadata": {},
   "source": [
    "Calling model on an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0f931cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd07f1cf",
   "metadata": {},
   "source": [
    "## Optimising the model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad74ede",
   "metadata": {},
   "source": [
    "Defining a loss function and optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e561497",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a301a4",
   "metadata": {},
   "source": [
    "Defining training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7438222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223f1172",
   "metadata": {},
   "source": [
    "Checking model's performance against the test dataset to ensure its learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f3df25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3008a5c7",
   "metadata": {},
   "source": [
    "Training over 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1efa01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.846119  [    1/   18]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.640686 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.665241  [    1/   18]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.625947 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.618914  [    1/   18]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.609701 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.654049  [    1/   18]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.593852 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.483647  [    1/   18]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.577453 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.394064  [    1/   18]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.563630 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.700535  [    1/   18]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.552275 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.281329  [    1/   18]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.543642 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.233808  [    1/   18]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.537386 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.646530  [    1/   18]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.533490 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.154535  [    1/   18]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.530866 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.152746  [    1/   18]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.529033 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.604965  [    1/   18]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.527751 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.699203  [    1/   18]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.527002 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.102377  [    1/   18]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.526322 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.718727  [    1/   18]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.525646 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.084386  [    1/   18]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.524688 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.065481  [    1/   18]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.524108 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.061397  [    1/   18]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.523251 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.721679  [    1/   18]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.522293 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0299a85",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c36b7f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to BW_model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"BW_model.pth\")\n",
    "print(\"Saved PyTorch Model State to BW_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73113f1",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cda013c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"BW_model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90cb74f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"White\", Actual: \"White\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"Black\",\n",
    "    \"White\"\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = testing_set[0][0], testing_set[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1496f965",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
